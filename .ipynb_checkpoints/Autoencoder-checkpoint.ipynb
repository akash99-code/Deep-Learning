{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e69f9e48",
   "metadata": {},
   "source": [
    "## Auotencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b083d",
   "metadata": {},
   "source": [
    "**packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "006244b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1da4ac5",
   "metadata": {},
   "source": [
    "**Loading MNIST dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32a25204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist_data = datasets.MNIST(root = \"./data\",\n",
    "                         train = True,\n",
    "                         download = True,\n",
    "                         transform = transforms.ToTensor())\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b0b33",
   "metadata": {},
   "source": [
    "**Creating Train Data Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf5b2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = mnist_data, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f6a359",
   "metadata": {},
   "source": [
    "**Building Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9d473f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(784, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 32)\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(32, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 784),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1493c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder()\n",
    "MSE = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay=0.0000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "affb51d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(epochs):\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        for (images, labels) in train_loader:\n",
    "            encoded, decoded = model(images)\n",
    "\n",
    "            loss = MSE(decoded, images.reshape(-1, 784))\n",
    "            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.steptorch()\n",
    "\n",
    "            losses.append(loss)\n",
    "            \n",
    "        print('Mean Loss after epoch ',epoch,':', loss.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55900da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss after epoch  0 : tensor(0.0216, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  1 : tensor(0.0163, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  2 : tensor(0.0118, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  3 : tensor(0.0130, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  4 : tensor(0.0081, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  5 : tensor(0.0081, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  6 : tensor(0.0098, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  7 : tensor(0.0077, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  8 : tensor(0.0082, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  9 : tensor(0.0056, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  10 : tensor(0.0089, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  11 : tensor(0.0075, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  12 : tensor(0.0063, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  13 : tensor(0.0078, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  14 : tensor(0.0078, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  15 : tensor(0.0068, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  16 : tensor(0.0067, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  17 : tensor(0.0060, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  18 : tensor(0.0065, grad_fn=<MeanBackward0>)\n",
      "Mean Loss after epoch  19 : tensor(0.0055, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "trainer(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77a155c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model\\\\auto_encoder_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto_encoder_model.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py:376\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \n\u001b[0;32m    342\u001b[0m \u001b[38;5;124;03mSaves an object to a disk file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    374\u001b[0m _check_dill_version(pickle_module)\n\u001b[1;32m--> 376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    378\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model\\\\auto_encoder_model.pth'"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), os.path.join('model', 'auto_encoder_model.pth.tar'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc0dda0",
   "metadata": {},
   "source": [
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "02d2c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels  = next(iter(loader))\n",
    "encoded, decoded = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "23150212",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = decoded.reshape(-1, 28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.imshow(decoded[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e61e9ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdecoded\u001b[49m[i]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'decoded' is not defined"
     ]
    }
   ],
   "source": [
    "decoded[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124daf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ec7d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a0e801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c4ae12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649af292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660e04f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d1bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Plot Style\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Plotting the last 100 values\n",
    "plt.plot(losses[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffe3fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, item in enumerate(image):\n",
    "   \n",
    "  # Reshape the array for plotting\n",
    "  item = item.reshape(-1, 28, 28)\n",
    "  plt.imshow(item[0])\n",
    " \n",
    "for i, item in enumerate(reconstructed):\n",
    "  item = item.reshape(-1, 28, 28)\n",
    "  plt.imshow(item[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
